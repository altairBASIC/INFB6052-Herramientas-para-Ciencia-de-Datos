{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "p_chA4mio1iH",
      "metadata": {
        "id": "p_chA4mio1iH"
      },
      "source": [
        "# Tarea: Mapa paralelo ‚Äî Comparaci√≥n de herramientas (Comercial vs Open Source)\n",
        "**Curso: HERRAMIENTAS PARA CIENCIA DE DATOS**  \n",
        "**Integrantes: Ignacio Ram√≠rez, Antonia Montecinos, Cristian Vergara**  \n",
        "**Profesor(a): MICHAEL GABRIEL MIRANDA SANDOVAL**  \n",
        "**Fecha de entrega: 05-11-2025**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uP0Ux-Tv5EXl",
      "metadata": {
        "id": "uP0Ux-Tv5EXl"
      },
      "source": [
        "## 1. Introducci√≥n y Objetivo \n",
        "\n",
        "En esta investigaci√≥n comparamos **AWS Glue** (comercial, servicio gestionado en AWS) y **Apache Airflow** (open source) dentro del √≠tem **Orquestaci√≥n / ETL‚ÄìELT (DTS)**. El foco es **documental** y se basa en **ejemplos oficiales de terceros** (tutoriales, gu√≠as y blogs t√©cnicos) correctamente referenciados. No implementamos c√≥digo propio nuevo; describimos y analizamos flujos ya publicados y sus implicancias pr√°cticas.\n",
        "\n",
        "**Contexto y motivaci√≥n.** Muchas organizaciones deben elegir entre un **motor ETL gestionado** (p. ej., Glue/Spark) y un **orquestador agn√≥stico al motor** (Airflow). Elegir incorrectamente introduce fricci√≥n (coste, gobernanza, mantenimiento y time-to-value). Esta investigaci√≥n busca aportar criterios concretos para decidir.\n",
        "\n",
        "**Objetivo general.** Evaluar ventajas, desventajas y casos de uso recomendados de AWS Glue y Apache Airflow para pipelines de datos de ingesta, transformaci√≥n y carga.\n",
        "\n",
        "**Objetivos espec√≠ficos.**\n",
        "1. **Caracterizar** el rol de cada herramienta (motor ETL vs orquestador) y su ecosistema.\n",
        "2. **Describir** uno o m√°s ejemplos can√≥nicos de uso.\n",
        "3. **Comparar** en criterios t√©cnicos y operativos: prototipado, escalabilidad, coste, integraciones, reproducibilidad y gobernanza.\n",
        "4. **Recomendar** cu√°ndo usar cada opci√≥n (empresa peque√±a vs grande; mono-nube vs multi-nube).\n",
        "\n",
        "\n",
        "**Metodolog√≠a.**\n",
        "- Selecci√≥n de **fuentes primarias** (docs oficiales) y **secundarias** (blogs t√©cnicos de AWS/Apache).\n",
        "- Extracci√≥n de: arquitectura, pasos, dependencias, outputs, requisitos y notas de operaci√≥n.\n",
        "- S√≠ntesis comparativa con **tabla** y **preguntas gu√≠a**.\n",
        "- Revisi√≥n por pares (equipo) para sesgos y coherencia.\n",
        "\n",
        "**Preguntas gu√≠a:**\n",
        "- ¬øCu√°l sirve mejor para prototipado r√°pido? ¬øy para producci√≥n?  \n",
        "- ¬øImplicancias de coste/gobernanza?  \n",
        "- ¬øLimitaciones vistas en documentaci√≥n/ejemplos?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b49df296",
      "metadata": {
        "id": "b49df296"
      },
      "source": [
        "## Resumen ejecutivo (150‚Äì200 palabras) \n",
        "\n",
        "Este trabajo compara AWS Glue (comercial) y Apache Airflow (open source) para orquestaci√≥n y ejecuci√≥n de flujos ETL/ELT. Se basa exclusivamente en ejemplos de terceros: tutoriales oficiales de AWS y de Apache Airflow que muestran pipelines b√°sicos de ingesta, transformaci√≥n y carga. Metodol√≥gicamente, documentamos los pasos, dependencias y resultados descritos por esas fuentes, sin implementar c√≥digo nuevo.\n",
        "### hallazgos principales\n",
        "(1) AWS Glue es un servicio ETL serverless gestionado, √≥ptimo para transformaciones pesadas con Apache Spark dentro del ecosistema AWS; expone un editor visual (Glue Studio) que acelera el prototipado y genera c√≥digo PySpark editable.\n",
        "\n",
        "\n",
        "(2) Apache Airflow es un orquestador puro y agn√≥stico al motor, con gran flexibilidad en Python y ecosistema de providers; requiere administrar infraestructura (Docker/Kubernetes/VM) y una base de metadatos.\n",
        "\n",
        " En costes, Glue cobra por uso (DPU-hora) y reduce la operaci√≥n de servidores, mientras que Airflow es software libre pero demanda recursos de operaci√≥n 24/7 para scheduler/webserver/workers.\n",
        "\n",
        "### Recomendacion\n",
        " **Glue** es preferible para ETL de **alto volumen centrado en AWS** y equipos que priorizan velocidad operativa con menor gesti√≥n. **Airflow** es preferible como **orquestador central** en entornos **multi-nube** o con diversidad de motores; suele **complementar** a Glue en producci√≥n orquestando jobs propios de Glue/DBT/SQL. Para una pyme 100% AWS: Glue + Step Functions/Airflow ligero; para una empresa con m√∫ltiples plataformas: Airflow como plano de orquestaci√≥n y motores especializados por tarea."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZSLFXAlO95-m",
      "metadata": {
        "id": "ZSLFXAlO95-m"
      },
      "source": [
        "## 2. Selecci√≥n de Herramientas \n",
        "\n",
        "**√çtem:**  \n",
        "Orquestaci√≥n / ETL‚ÄìELT (DTS)\n",
        "\n",
        "**Comercial :**  \n",
        "AWS Glue (servicio gestionado en AWS; documentaci√≥n oficial, versi√≥n 2025)\n",
        "\n",
        "**Open Source:**  \n",
        "Apache Airflow v3.1.1 (versi√≥n estable; documentaci√≥n consultada 3-Nov-2025)\n",
        "\n",
        "**Justificaci√≥n breve :**  \n",
        "Seleccionamos AWS Glue y Apache Airflow por representar dos enfoques complementarios de orquestaci√≥n de datos.  \n",
        "AWS Glue ofrece un modelo ETL totalmente gestionado y serverless con motor Spark y editor visual (Glue Studio), ideal para pipelines sobre infraestructura AWS con bajo mantenimiento.  \n",
        "Apache Airflow, en cambio, es un orquestador open source y agn√≥stico al motor, orientado a flujos heterog√©neos (SQL, Spark, APIs) y ampliamente adoptado en entornos multi-nube, aunque requiere administraci√≥n de infraestructura (scheduler/webserver/workers).\n",
        "\n",
        "**Ejemplo(s) de terceros usados (enlace ‚Äî autor/organizaci√≥n ‚Äî fecha ‚Äî qu√© parte se usa):**\n",
        "\n",
        "1. **AWS Glue ‚Äî Tutorial oficial (Crawler + Cat√°logo)**  \n",
        "   - Enlace: https://docs.aws.amazon.com/glue/latest/dg/tutorial-add-crawler.html\n",
        "   - Autor/Organizaci√≥n: AWS Docs  \n",
        "   - Fecha: Accedido 3-Nov-2025 (¬© 2025)  \n",
        "   - Parte usada: Ejemplo de creaci√≥n de Crawler para inferir esquema desde S3 y registrar tablas en Glue Data Catalog.\n",
        "\n",
        "2. **AWS Glue Studio ‚Äî Blog de AWS Big Data (pipeline extremo a extremo)**  \n",
        "   - Enlace:https://aws.amazon.com/blogs/big-data/end-to-end-development-lifecycle-for-data-engineers-to-build-a-data-integration-pipeline-using-aws-glue\n",
        "   - Autor/Organizaci√≥n: AWS Big Data Blog (Noritaka Sekiyama)  \n",
        "   - Fecha: 26-Jul-2023  \n",
        "   - Parte usada: Flujo de dise√±o e implementaci√≥n de jobs ETL con Glue Studio, integraci√≥n con S3, Redshift y CDK.\n",
        "\n",
        "3. **Apache Airflow ‚Äî Tutorial oficial (Pipeline simple con Postgres)**  \n",
        "   - Enlace: https://airflow.apache.org/docs/apache-airflow/stable/tutorial/pipeline.html\n",
        "   - Autor/Organizaci√≥n: Apache Airflow Docs  \n",
        "   - Fecha: Documentaci√≥n v3.1.1 (consultado 3-Nov-2025)  \n",
        "   - Parte usada: Ejemplo DAG que descarga CSV, carga en Postgres y aplica transformaciones SQL; base para comparaci√≥n con Glue.\n",
        "\n",
        "4. **Apache Airflow ‚Äî TaskFlow API (ETL Python-first)**  \n",
        "   - Enlace: https://airflow.apache.org/docs/apache-airflow/stable/tutorial/taskflow.html\n",
        "   - Autor/Organizaci√≥n: Apache Airflow Docs  \n",
        "   - Fecha: Documentaci√≥n v3.1.1 (consultado 3-Nov-2025)  \n",
        "   - Parte usada: Ejemplo ETL modular con decoradores @dag y @task; muestra flujos nativos Python y visualizaci√≥n DAG.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10d3cde6",
      "metadata": {
        "id": "10d3cde6"
      },
      "source": [
        "# 3. Configuraci√≥n del Entorno\n",
        "\n",
        "- **Entorno Comercial (AWS Glue):**\n",
        "  - Requiere una cuenta activa de AWS.\n",
        "  - Recursos m√≠nimos: bucket(s) S3 (origen/destino), rol IAM para Glue (por ejemplo, `AWSGlueServiceRole-*`), y opcionalmente destino anal√≠tico (Amazon Redshift/RDS/Athena).\n",
        "  - Toda la configuraci√≥n es v√≠a consola AWS (Glue Studio, S3, IAM). El job corre en Spark serverless (DPUs administradas por AWS).\n",
        "\n",
        "- **Entorno Open Source (Apache Airflow):**\n",
        "  - Requiere una instancia de Airflow; el tutorial oficial usa Docker + Docker Compose.\n",
        "  - Componentes: scheduler, webserver, base de metadatos, y workers (seg√∫n deployment).\n",
        "  - Paquetes/Providers de ejemplo: `apache-airflow`, `apache-airflow-providers-postgres`, `requests`.\n",
        "  - Recursos: contenedor Postgres (para el tutorial) y conexiones definidas en la UI (por ej., `tutorial_pg_conn`)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WXgLcB-Wjb62",
      "metadata": {
        "id": "WXgLcB-Wjb62"
      },
      "source": [
        "# 4. Ejemplo de Uso: Herramienta Comercial (AWS Glue) (mooodificado)\n",
        "\n",
        "En esta secci√≥n se documenta un ejemplo de uso de la herramienta **comercial seleccionada (AWS Glue)**.  \n",
        "No se implement√≥ el ejemplo directamente, sino que se basa en **documentaci√≥n y tutoriales oficiales** de AWS que muestran el flujo completo de un pipeline ETL.  \n",
        "\n",
        "---\n",
        "\n",
        "###  Fuente principal\n",
        "- **T√≠tulo:** *Adding an AWS Glue Crawler*  \n",
        "- **Enlace:** [https://docs.aws.amazon.com/glue/latest/dg/tutorial-add-crawler.html](https://docs.aws.amazon.com/glue/latest/dg/tutorial-add-crawler.html)  \n",
        "- **Autor/Organizaci√≥n:** AWS Docs  \n",
        "- **Fecha:** Accedido 3-Nov-2025 (¬© 2025)  \n",
        "\n",
        "**Qu√© hace el ejemplo:**  \n",
        "Crea y ejecuta un *Crawler* que analiza archivos CSV almacenados en un bucket S3, infiere autom√°ticamente su esquema y los registra en el **Glue Data Catalog**, dejando las tablas disponibles para futuros trabajos ETL.  \n",
        "\n",
        "**Resultados generados:**  \n",
        "- Tablas catalogadas con columnas, tipos de datos y particiones inferidas.  \n",
        "- Registro autom√°tico en el cat√°logo, visible en la consola AWS Glue Studio.  \n",
        "- Punto de partida para ejecutar jobs ETL visuales o basados en PySpark.  \n",
        "\n",
        "---\n",
        "\n",
        "![Creacion de un Crawler](fotos/fuente1..png)\n",
        "\n",
        "###  Fuente complementaria\n",
        "- **T√≠tulo:** *End-to-End Development Lifecycle for Data Engineers using AWS Glue*  \n",
        "- **Enlace:** [https://aws.amazon.com/blogs/big-data/end-to-end-development-lifecycle-for-data-engineers-to-build-a-data-integration-pipeline-using-aws-glue](https://aws.amazon.com/blogs/big-data/end-to-end-development-lifecycle-for-data-engineers-to-build-a-data-integration-pipeline-using-aws-glue)  \n",
        "- **Autor/Organizaci√≥n:** AWS Big Data Blog (Autor: Noritaka Sekiyama)  \n",
        "- **Fecha:** 26-Jul-2023  \n",
        "\n",
        "**Qu√© hace el ejemplo:**  \n",
        "Muestra un pipeline de integraci√≥n de datos completo desarrollado con **AWS Glue Studio** y **AWS CDK**, abarcando las etapas *Plan ‚Üí Design ‚Üí Implement ‚Üí Test ‚Üí Deploy ‚Üí Maintain*.  \n",
        "Incluye la creaci√≥n de buckets S3, definici√≥n de roles IAM, desarrollo de scripts PySpark, testing con Docker y despliegue automatizado mediante CodePipeline y CodeCommit.  \n",
        "\n",
        "**Resultados generados:**  \n",
        "- Job ETL que lee datos JSON desde S3, aplica transformaciones con Spark y los escribe en Redshift/S3.  \n",
        "- Grafo visual del flujo en Glue Studio (fuente ‚Üí transform ‚Üí destino).  \n",
        "- M√©tricas de ejecuci√≥n y uso de DPU (Spark serverless).  \n",
        "\n",
        "\n",
        "![diagrama pipeline](fotos/fuente22.png)\n",
        "---\n",
        "\n",
        "###  Reproducibilidad del ejemplo\n",
        "Los ejemplos de AWS Glue **son ejecutables por terceros** mediante una cuenta activa en AWS.  \n",
        "Para reproducirlos, basta con:\n",
        "1. Crear un bucket S3 con datos de muestra (por ejemplo, archivos CSV p√∫blicos).  \n",
        "2. Crear un *Crawler* siguiendo el tutorial oficial y registrar el esquema en Glue Data Catalog.  \n",
        "3. Dise√±ar un job ETL en Glue Studio con origen S3 ‚Üí transformaci√≥n Spark ‚Üí destino S3/Redshift.  \n",
        "\n",
        "No se ejecut√≥ en este trabajo porque AWS Glue requiere **recursos facturables (DPU-hora)** y **roles IAM activos**; sin embargo, los pasos de reproducci√≥n est√°n completamente documentados en las fuentes oficiales citadas.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### üí¨ Observaciones\n",
        "- **Facilidad de uso:** Alta; el editor visual de Glue Studio acelera la creaci√≥n de flujos sin requerir configuraci√≥n de cl√∫steres Spark.  \n",
        "- **Coste:** Basado en consumo (*pago por DPU-hora*); sin costos fijos de infraestructura.  \n",
        "- **Limitaciones:** Dependencia total del ecosistema AWS (lock-in).  \n",
        "- **Ventajas:** Orquestaci√≥n simple, entorno serverless, y despliegue gestionado.  \n",
        "- **Cr√©ditos:** Ejemplo documentado oficialmente por AWS Docs y AWS Big Data Blog.\n",
        " Parte 5 ‚Äì Ejemplo de Uso: Herramienta Open Source (Apache Airflow)\n",
        "(con el mismo formato oficial que tu gu√≠a)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aTePAvaxoFam",
      "metadata": {
        "id": "aTePAvaxoFam"
      },
      "source": [
        "## 5. Ejemplo de Uso: Herramienta Open Source (Apache Airflow)  (modificado)\n",
        "\n",
        "En esta secci√≥n se documenta un ejemplo de uso de la herramienta **open source seleccionada (Apache Airflow)**.  \n",
        "El contenido proviene de ejemplos oficiales publicados en la documentaci√≥n de Apache y muestra el flujo completo de un pipeline ETL orquestado en Airflow.\n",
        "\n",
        "---\n",
        "\n",
        "###  Fuente principal\n",
        "- **T√≠tulo:** *Building a Simple Data Pipeline*  \n",
        "- **Enlace:** [https://airflow.apache.org/docs/apache-airflow/stable/tutorial/pipeline.html](https://airflow.apache.org/docs/apache-airflow/stable/tutorial/pipeline.html)  \n",
        "- **Autor/Organizaci√≥n:** Apache Airflow Docs  \n",
        "- **Fecha:** Consultado 3-Nov-2025 (versi√≥n 3.1.1)  \n",
        "\n",
        "**Qu√© hace el ejemplo:**  \n",
        "Define un DAG que (1) descarga un archivo CSV, (2) lo carga a una tabla staging en PostgreSQL y (3) ejecuta tareas de limpieza y combinaci√≥n de datos usando operadores SQL (`SQLExecuteQueryOperator`, `PostgresHook`).  \n",
        "Incluye el uso de Docker Compose para inicializar el entorno (scheduler, webserver, database).  \n",
        "\n",
        "**Resultados generados:**  \n",
        "- DAG ejecutable y visualizable en la interfaz web (List, Graph y Grid views).  \n",
        "- Logs detallados por tarea y estado de ejecuci√≥n (*success, failed, retry*).  \n",
        "- Pipeline reproducible localmente v√≠a Docker con base de datos Postgres.  \n",
        "\n",
        "![aa](fotos/fuente3.png)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "###  Fuente complementaria\n",
        "- **T√≠tulo:** *Pythonic DAGs with the TaskFlow API*  \n",
        "- **Enlace:** [https://airflow.apache.org/docs/apache-airflow/stable/tutorial/taskflow.html](https://airflow.apache.org/docs/apache-airflow/stable/tutorial/taskflow.html)  \n",
        "- **Autor/Organizaci√≥n:** Apache Airflow Docs  \n",
        "- **Fecha:** Consultado 3-Nov-2025 (versi√≥n 3.1.1)  \n",
        "\n",
        "**Qu√© hace el ejemplo:**  \n",
        "Implementa un flujo ETL usando la API *TaskFlow*, que simplifica la definici√≥n de dependencias mediante decoradores `@dag` y `@task`.  \n",
        "Muestra c√≥mo pasar datos entre tareas y visualizar dependencias en la UI de Airflow.\n",
        "\n",
        "**Resultados generados:**  \n",
        "- DAG modular con dependencias tipo `t1 >> t2 >> t3`.  \n",
        "- Captura de vista Graph mostrando tareas enlazadas.  \n",
        "- Ejecuci√≥n exitosa con celdas en verde y logs por tarea.\n",
        "\n",
        "---\n",
        "\n",
        "###  Reproducibilidad del ejemplo\n",
        "Los ejemplos de Apache Airflow **pueden reproducirse localmente** mediante Docker Compose, utilizando los archivos disponibles en la documentaci√≥n oficial.  \n",
        "Pasos generales:\n",
        "1. Instalar Docker y Docker Compose.  \n",
        "2. Clonar o crear la estructura del proyecto con el archivo `docker-compose.yaml` provisto por Apache.  \n",
        "3. Ejecutar los comandos:\n",
        "   ```bash\n",
        "   docker compose up airflow-init\n",
        "   docker compose u\n",
        "\n",
        "---\n",
        "\n",
        "### üí¨ Observaciones\n",
        "- **Facilidad de uso:** Moderada; requiere instalaci√≥n o despliegue con Docker, pero otorga total flexibilidad sobre los flujos.  \n",
        "- **Extensibilidad:** Muy alta; se integra con *providers* oficiales para AWS, GCP, Azure, Databricks, DBT y APIs externas.  \n",
        "- **Mantenimiento:** Requiere operaci√≥n del scheduler, base de metadatos y workers (mayor carga operativa que Glue).  \n",
        "- **Ventajas:** Orquestador agn√≥stico, adaptable y est√°ndar en la industria OSS.  \n",
        "- **Comunidad:** Amplia, activa y con soporte continuo de Apache Foundation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- **Evidencia (c√≥digo y capturas, seg√∫n docs):**\n",
        "  - Fragmento conceptual: Definici√≥n de DAG (TaskFlow/Operators) y dependencias tipo `t1 >> t2 >> t3` (o invocaci√≥n funcional TaskFlow).\n",
        "  - Captura 1: Vista Graph con las 3 tareas y sus dependencias.\n",
        "  - Captura 2: Vista Grid mostrando una corrida exitosa (celdas en verde) y acceso a logs por tarea.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uB0_KOst0xfI",
      "metadata": {
        "id": "uB0_KOst0xfI"
      },
      "source": [
        "# 6. Comparaci√≥n de la Herramientas (modificado)\n",
        "\n",
        "En esta secci√≥n se comparan de forma estructurada los resultados  con ambas herramientas: **AWS Glue (comercial)** y **Apache Airflow (open source)**.  \n",
        "Dado que los ejemplos utilizados provienen de documentaci√≥n oficial, la comparaci√≥n se centra en **criterios t√©cnicos y pr√°cticos** observados en la documentaci√≥n, en la facilidad de uso y en el enfoque arquitect√≥nico de cada soluci√≥n.\n",
        "\n",
        "| Criterio | Comercial (AWS Glue) | Open Source (Apache Airflow) | Observaciones | Recomendaci√≥n |\n",
        "|---|---|---|---|---|\n",
        "| **Rol principal** | Motor ETL serverless (Spark) + orquestaci√≥n simple | Orquestador puro (agn√≥stico al motor) | Glue ejecuta el Spark; Airflow coordina y puede disparar jobs de Glue | Se complementan |\n",
        "| **Facilidad de prototipado** | Alta (Glue Studio visual) | Alta (c√≥digo + TaskFlow) | Glue acelera el desarrollo sin configurar cl√∫steres; Airflow requiere definir tareas manualmente. | Glue para ETL r√°pido en AWS; Airflow para flujos personalizados. |\n",
        "| **Escalabilidad y rendimiento** | Autom√°tica (DPU administradas por AWS, escalado transparente) | Depende de workers/cluster |Glue escala sin intervenci√≥n; Airflow escala horizontalmente en Kubernetes o Celery | Glue en workloads controlados, Airflow en entornos distribuidos |\n",
        "| **Coste y modelo de uso** | Pago por DPU-hora | Gratuito (licencia OSS) pero requiere infraestructura y mantenimiento | Glue implica gasto operativo (OpEx); Airflow implica coste de operaci√≥n local (infra/tiempo) |Airflow si ya se dispone de infraestructura; Glue si se busca simplicidad |\n",
        "| **Integraciones** | Nativas AWS (S3, Redshift, RDS, IAM) | Provedores (AWS/GCP/Azure/DBs/APIs) | Glue depende del ecosistema AWS; Airflow es agn√≥stico | Airflow para multi-nube; Glue para entornos 100% AWS |\n",
        "| **Documentaci√≥n y soporte** | Muy detallada (AWS Docs, blogs oficiales, ejemplos GUI) | Extensa y comunitaria (Apache Docs, foros, GitHub) | Glue ofrece gu√≠as visuales; Airflow tiene documentaci√≥n extensa y t√©cnica | Glue m√°s visual, Airflow m√°s t√©cnico |\n",
        "| **Facilidad de acceso y reproducci√≥n** | Requiere cuenta AWS y permisos IAM | Requiere entorno Docker local (documentaci√≥n oficial) |Ambos reproducibles; Glue en nube, Airflow en local | Depende del entorno del usuario (cloud vs on-premise) |\n",
        "| **Curva de aprendizaje** | Media (Spark, IAM, AWS) | Media-Alta (DAGs, Docker/K8s) | Perfila al equipo: data engineers vs. platform/devops | Depende del equipo |\n",
        "\n",
        "### Preguntas gu√≠a\n",
        "- **Prototipado r√°pido:** Glue Studio es muy r√°pido para ETL de Spark en AWS; Airflow es √°gil para definir flujos heterog√©neos de tareas.\n",
        "- **Producci√≥n:** Usualmente se combinan. Airflow orquesta y llama jobs de Glue dentro de un DAG.\n",
        "- **Coste/Gobernanza:** Glue es OpEx por uso; Airflow implica coste de infraestructura y operaci√≥n. Glue integra IAM; Airflow gestiona usuarios/roles en su propio stack.\n",
        "- **Limitaciones:** Glue: vendor lock-in y orquestaci√≥n simple. Airflow: no procesa datos por s√≠ mismo y requiere mantenimiento."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53ROAm_s5zey",
      "metadata": {
        "id": "53ROAm_s5zey"
      },
      "source": [
        "## 7. Conclusiones y Reflexi√≥n (modificado)\n",
        "\n",
        "El an√°lisis comparativo entre **AWS Glue** (herramienta comercial) y **Apache Airflow** (herramienta open source) permite extraer conclusiones claras sobre sus **enfoques, fortalezas y limitaciones** en el √°mbito de la orquestaci√≥n y ejecuci√≥n de flujos ETL/ELT.\n",
        "\n",
        "---\n",
        "\n",
        "###  Conclusiones t√©cnicas\n",
        "\n",
        "**AWS Glue**  \n",
        "- Representa un enfoque *ETL gestionado y serverless*, √≥ptimo para entornos completamente integrados en AWS.  \n",
        "- Su editor visual (Glue Studio) facilita el **prototipado r√°pido** sin requerir configuraci√≥n de infraestructura ni cl√∫steres Spark.  \n",
        "- Ofrece escalabilidad autom√°tica y seguridad centralizada mediante IAM.  \n",
        "- Principal limitaci√≥n: **dependencia del ecosistema AWS (vendor lock-in)**, con escasa flexibilidad fuera de su entorno.\n",
        "\n",
        "**Apache Airflow**  \n",
        "- Es un **orquestador agn√≥stico** y programable, que se adapta a cualquier motor o servicio (Spark, SQL, DBT, APIs, etc.).  \n",
        "- Permite definir flujos complejos y reproducibles mediante c√≥digo Python, favoreciendo la **extensibilidad y mantenibilidad**.  \n",
        "- Su arquitectura requiere despliegue y mantenimiento (scheduler, webserver, metadatabase), lo que implica **mayor carga operativa**.  \n",
        "- Ideal para flujos **multi-nube o h√≠bridos**, donde se coordinen diversos servicios y fuentes de datos.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "Ambas herramientas **no compiten directamente**, sino que **se complementan**:  \n",
        "- Glue cumple el rol de **motor ETL serverless**, ejecutando transformaciones en Spark.  \n",
        "- Airflow act√∫a como **director/orquestador**, gestionando dependencias entre tareas y flujos heterog√©neos.  \n",
        "\n",
        "En la pr√°ctica, las empresas combinan ambos enfoques: Airflow puede disparar jobs de Glue o Spark, integr√°ndolos en pipelines unificados.  \n",
        "La elecci√≥n depende del **balance entre simplicidad, autonom√≠a t√©cnica y contexto de infraestructura**.\n",
        "\n",
        "---\n",
        "\n",
        "###  Recomendaciones seg√∫n contexto\n",
        "\n",
        "| Tipo de organizaci√≥n | Recomendaci√≥n |\n",
        "|----------------------|----------------|\n",
        "| **Peque√±a / 100% AWS** | Adoptar **AWS Glue** como soluci√≥n principal de ETL y orquestaci√≥n b√°sica, aprovechando su entorno serverless y escalabilidad autom√°tica. |\n",
        "| **Mediana o grande / multi-nube** | Utilizar **Apache Airflow** como orquestador central, integrando Glue, DBT, Databricks o SQL seg√∫n cada caso. |\n",
        "| **Equipos mixtos (data + devops)** | Combinar Glue para cargas ETL y Airflow para coordinar tareas y dependencias complejas. |\n",
        "\n",
        "---\n",
        "\n",
        "###  Reflexi√≥n final\n",
        "\n",
        "La documentaci√≥n de ambos proyectos demuestra dos filosof√≠as distintas:  \n",
        "- AWS Glue prioriza la **automatizaci√≥n y gobernanza gestionada**.  \n",
        "- Apache Airflow prioriza la **flexibilidad y estandarizaci√≥n abierta**.  \n",
        "\n",
        "Esta complementariedad refleja la evoluci√≥n natural del ecosistema de datos:  \n",
        "la orquestaci√≥n moderna no depende de una √∫nica herramienta, sino de la capacidad de integrarlas eficientemente dentro de una arquitectura escalable y reproducible.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8c466c1",
      "metadata": {
        "id": "f8c466c1"
      },
      "source": [
        "# Referencias\n",
        "\n",
        "1. AWS Docs. \"Tutorial: Adding an AWS Glue crawler\". URL: https://docs.aws.amazon.com/glue/latest/dg/tutorial-add-crawler.html (Accedido: 3-Nov-2025).\n",
        "2. AWS Big Data Blog (Noritaka Sekiyama). \"End-to-end development lifecycle for data engineers to build a data integration pipeline using AWS Glue\". URL: https://aws.amazon.com/blogs/big-data/end-to-end-development-lifecycle-for-data-engineers-to-build-a-data-integration-pipeline-using-aws-glue (Publicado: 26-Jul-2023).\n",
        "3. Apache Airflow Docs. \"Building a Simple Data Pipeline\" (Contenido versi√≥n 3.1.1). URL: https://airflow.apache.org/docs/apache-airflow/stable/tutorial/pipeline.html (Accedido: 3-Nov-2025).\n",
        "4. Apache Airflow Docs. \"Pythonic Dags with the TaskFlow API\" (Contenido versi√≥n 3.1.1). URL: https://airflow.apache.org/docs/apache-airflow/stable/tutorial/taskflow.html (Accedido: 3-Nov-2025)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37f97caf",
      "metadata": {
        "id": "37f97caf"
      },
      "source": [
        "# 8. Autores y Contribuciones\n",
        "\n",
        "- **Autor(es):** Ignacio Ram√≠rez, Antonia Montecinos, Cristian Vergara\n",
        "- **Contribuciones:**\n",
        "  - []: Jefe de Proyecto y Redactor Principal. Investigaci√≥n y redacci√≥n de secciones 4, 5, 6 y 7.\n",
        "  - []: Dise√±ador. B√∫squeda de ejemplos de terceros y creaci√≥n de la presentaci√≥n.\n",
        "  - []: Revisor t√©cnico. Validaci√≥n de criterios y referencias."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gX9vOcZF7C8w",
      "metadata": {
        "id": "gX9vOcZF7C8w"
      },
      "source": [
        "## Checklist de entrega (marcar antes de subir):\n",
        "- [x] Documento (notebook o PDF) con la investigaci√≥n y an√°lisis comparativo.\n",
        "- [x] Referencias completas a los ejemplos de terceros usados (link, autor/organizaci√≥n, fecha, breve descripci√≥n de uso).\n",
        "- [x] Evidencia visual o descriptiva de los ejemplos (capturas, tablas, o explicaci√≥n detallada).\n",
        "- [x] Archivo ZIP con recursos adicionales (opcional: datos, scripts) o enlace al repositorio fuente.\n",
        "- [x] Presentaci√≥n (diapositivas) o PDF para exponer en clase.\n",
        "- [] Archivo README breve con instrucciones sobre c√≥mo navegar la entrega (si aplica).\n",
        "- [] Archivo de referencias (opcional: `references.bib` o `REFERENCES.md`).\n",
        "- [] Declaraci√≥n de licencias / permisos para recursos externos (licencia OSS, permisos de uso de capturas, etc.).\n",
        "- [x] Autor(es) y contribuciones (lista de integrantes y roles ‚Äî qui√©n hizo qu√©).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

\input{preamble}\graphicspath{{./}}\begin{document}\GenerarPortada

\section{Fundamentos Teóricos}
El perceptrón busca un hiperplano lineal que separa dos clases. Dada una observación $x$, decide $\hat{y}=1$ si $w^Tx + b \ge 0$ y $0$ en caso contrario. La regla de aprendizaje incremental actualiza pesos sólo cuando existe un error: 
\[ w := w + \eta (y - \hat{y}) x, \qquad b := b + \eta (y - \hat{y}). \]
Se discuten conceptos de: separabilidad lineal, convergencia y limitaciones frente a clases no lineales.

\section{Dataset}
Se utiliza el dataset Breast Cancer Wisconsin (Diagnostic). Contiene 30 características derivadas de imágenes de células y una etiqueta binaria (maligno/benigno). Se aplicó escalado estándar (media 0, varianza 1). División: entrenamiento, validación y prueba estratificados.

\section{Implementación Scratch}
Se desarrolló una clase \texttt{PerceptronScratch} (sin librerías de ML) con:
\begin{itemize}
	\item Parámetros: tasa de aprendizaje, épocas, mezcla (shuffle), paciencia (early stopping), tolerancia de mejora.
	\item Registro de historia: errores por época, accuracy entrenamiento y validación, mejor época y convergencia anticipada.
	\item Exportación / importación a JSON (pesos y metadatos) para reproducibilidad.
	\item Early stopping por: (a) convergencia (cero errores) o (b) falta de mejora en validación.
\end{itemize}

\section{Metodología Experimental}
\subsection{Flujo}
\begin{enumerate}
	\item Preprocesamiento: escalado estándar.
	\item Entrenamiento perceptrón scratch con conjunto de validación para monitoreo.
	\item Búsqueda manual de hiperparámetros (rejilla pequeña de $\eta$ y épocas).
	\item Comparación con modelos de referencia: \texttt{Perceptron}, \texttt{SGDClassifier} (modo perceptrón) y \texttt{LogisticRegression} de scikit-learn.
	\item Evaluación en conjunto de prueba (hold-out) y validación cruzada estratificada (k=5) para robustez.
\end{enumerate}
\subsection{Artefactos}
Se generaron los siguientes archivos en \texttt{artifacts/} mediante el script CLI y el notebook:
\begin{itemize}
	\item \texttt{model\_perceptron.json}: pesos y configuración del modelo scratch.
	\item \texttt{metrics.json}: métricas finales sobre test.
	\item \texttt{training\_curve.csv}: evolución de errores y accuracies.
	\item \texttt{resumen\_modelos.csv}: comparación de modelos (notebook).
\end{itemize}

\section{Resultados}
Se reportan: accuracy, precision, recall, F1 y AUC ROC. El perceptrón scratch converge en \emph{n} épocas con \emph{e} errores finales (cero tras convergencia). Los modelos de scikit-learn muestran:
\begin{itemize}
	\item Mayor estabilidad frente a ruido y variaciones de tasa de aprendizaje.
	\item Mejor F1 en promedio (particularmente \texttt{LogisticRegression}).
	\item Menor tiempo de entrenamiento debido a optimizaciones internas.
\end{itemize}

\section{Discusión}
La implementación manual permite transparencia pedagógica (inspección de pesos, lógica de actualización), mientras que scikit-learn ofrece:
\begin{itemize}
	\item Mecanismos de regularización (L2, L1, elastic net) no presentes en la versión scratch.
	\item Mejor manejo de casos no separables y criterios de parada sofisticados.
	\item Integración nativa con pipelines y \texttt{GridSearchCV}.
\end{itemize}
Limitaciones del perceptrón: incapacidad para fronteras no lineales y ausencia de probabilidades calibradas.

\section{Conclusiones}
El perceptrón scratch cumple su objetivo formativo: ilustrar la dinámica de actualización y los conceptos de convergencia. Para aplicaciones productivas se recomienda emplear modelos con funciones de pérdida diferenciables (p.ej. regresión logística) o métodos que soporten regularización robusta. Extensiones propuestas incluyen añadir regularización L2, versión multiclase y análisis de sensibilidad a ruido.

\section{Reproducibilidad}
\begin{itemize}
	\item Script CLI: \texttt{train\_perceptron\_scratch.py} (ver README).
	\item Notebook comparativo: \texttt{perceptron\_comparativo.ipynb}.
	\item Semilla global: 42.
\end{itemize}

\bibliographystyle{plain}\bibliography{referencias}\end{document}

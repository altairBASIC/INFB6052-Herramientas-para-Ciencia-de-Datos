%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% INFORME PRIMERA PARTE - PRUEBA 1
%
% Informe Técnico: Implementación de 5 Ejercicios Prácticos en Ciencia de Datos
% Curso: INFB6052 - Herramientas para Cs. de Datos
%
% Autor: Ignacio Ramírez, Cristian Vergara, Antonia Montecinos
% Grupo: 2
% Fecha: Octubre 2025
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[12pt]{src/formato_utem}
\usepackage{background} 
\usepackage{url}        
\usepackage{hyperref}   

% --- Configuración del Documento ---
\backgroundsetup{contents={}} 
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}

% --- Información para la Portada ---
\setuniversidad{Universidad Tecnológica Metropolitana}
\setcarrera{Ingeniería Civil en Ciencia de Datos}
\setcodcurso{INFB6052}
\setnombrecurso{Herramientas para Cs. de Datos}
\setfecha{Segundo Semestre de 2025}

% Títulos específicos para este entregable
\setencactividad{Informe Primera Parte - Prueba 1: \\}
\setdescactividad{Implementación de 5 Ejercicios Prácticos en Ciencia de Datos}

\begin{document}
\pagestyle{fancy}
\makemytitle

\newpage

% --- Inicio del Contenido del Informe ---

\tituloazul{Informe de la Primera Parte: }

%-------------------------------------------------------------------------------
\section*{(i) Introducción}
%-------------------------------------------------------------------------------

Este informe presenta la documentación técnica de la \textbf{Primera Parte} de la Prueba 1 del curso INFB6052 - Herramientas para Ciencia de Datos. El trabajo consta de cinco ejercicios prácticos que abarcan aspectos fundamentales del ecosistema de herramientas modernas para el análisis y procesamiento de datos a gran escala.

\subsection*{Objetivos Generales}

El objetivo principal de esta primera parte es demostrar competencia práctica en:

\begin{itemize}
    \item \textbf{Comparación de paradigmas de almacenamiento}: SQL vs NoSQL en contextos reales.
    \item \textbf{Manejo de grandes volúmenes de datos}: Técnicas de ingestión y procesamiento de datasets superiores a 200 MB sin almacenamiento local completo.
    \item \textbf{Evaluación de frameworks de procesamiento}: Comparación empírica entre Pandas y PySpark.
    \item \textbf{Análisis de librerías de visualización}: Evaluación sistemática de Matplotlib, Seaborn y Plotly.
    \item \textbf{Implementación de algoritmos desde cero}: Desarrollo del Perceptrón sin librerías de Machine Learning.
\end{itemize}

\subsection*{Estructura del Informe}

El documento está organizado en cinco secciones principales, cada una correspondiente a un ejercicio:

\begin{enumerate}
    \item \textbf{Comparación SQL vs NoSQL}: Análisis de bases de datos tabulares y no tabulares.
    \item \textbf{Pipeline de Ingestión de Datos Grandes}: Estrategias para datasets $\geq$ 200 MB.
    \item \textbf{Pandas vs PySpark}: Comparación de rendimiento y casos de uso.
    \item \textbf{Librerías de Visualización}: Evaluación de Matplotlib, Seaborn y Plotly.
    \item \textbf{Perceptrón desde Cero}: Implementación y validación del algoritmo clásico.
\end{enumerate}

Cada sección incluye: objetivos específicos, metodología, implementación técnica, resultados y conclusiones.

\newpage

%-------------------------------------------------------------------------------
\section*{(ii) Ejercicio 1: Comparación de Bases de Datos SQL vs NoSQL}
%-------------------------------------------------------------------------------

\subsection*{Objetivos}

\begin{itemize}
    \item Comparar el rendimiento de bases de datos tabulares (SQL) y no tabulares (NoSQL) en operaciones comunes de carga y consulta.
    \item Analizar datasets de diferentes naturalezas: datos estructurados (transacciones financieras) y datos no estructurados (texto).
    \item Evaluar ventajas y desventajas de cada paradigma en contextos específicos.
\end{itemize}

\subsection*{Datasets Utilizados}

\subsubsection*{Dataset Tabular: Fraude en Transacciones Bancarias}

\textbf{Fuente:} Kaggle - \href{https://www.kaggle.com/datasets/kartik2112/fraud-detection}{Fraud Detection Dataset}

\textbf{Características:}
\begin{itemize}
    \item \textbf{Archivos:} \texttt{fraudTrain.csv} y \texttt{fraudTest.csv}
    \item \textbf{Total de registros:} Aproximadamente 1,850,000 transacciones combinadas
    \item \textbf{Columnas principales:} 
    \begin{itemize}
        \item \texttt{trans\_date\_trans\_time}: Timestamp de la transacción
        \item \texttt{merchant}: Comerciante
        \item \texttt{category}: Categoría de compra
        \item \texttt{amt}: Monto de la transacción
        \item \texttt{lat}, \texttt{long}: Coordenadas geográficas
        \item \texttt{is\_fraud}: Etiqueta binaria (0 = legítima, 1 = fraudulenta)
    \end{itemize}
    \item \textbf{Periodo:} 1 de enero de 2019 - 31 de diciembre de 2020
\end{itemize}

\textbf{Justificación:} Dataset ideal para demostrar el rendimiento de bases de datos relacionales en operaciones de agregación, filtrado y joins sobre datos estructurados.

\subsubsection*{Dataset No Tabular: WikiSent2}

\textbf{Fuente:} Corpus de texto no estructurado derivado de Wikipedia

\textbf{Características:}
\begin{itemize}
    \item \textbf{Archivo:} \texttt{wikisent2.txt}
    \item \textbf{Contenido:} Aproximadamente 500,000 líneas de texto en formato libre
    \item \textbf{Estructura:} Sin esquema fijo, texto puro con variabilidad en longitud y formato
\end{itemize}

\textbf{Justificación:} Representa el tipo de datos que requiere flexibilidad de esquema, ideal para bases NoSQL orientadas a documentos.

\subsection*{Implementación}

\subsubsection*{Herramientas Utilizadas}

\begin{itemize}
    \item \textbf{Pandas:} Carga y análisis exploratorio de datos tabulares
    \item \textbf{SQLite:} Base de datos relacional embebida para comparación SQL
    \item \textbf{MongoDB:} Base de datos NoSQL orientada a documentos (simulado con diccionarios Python para el análisis)
    \item \textbf{Matplotlib:} Visualización de métricas comparativas
\end{itemize}

\subsubsection*{Flujo de Trabajo}

El notebook \texttt{tab-vs-notab.ipynb} implementa el siguiente pipeline:

\begin{enumerate}
    \item \textbf{Carga de Datos Tabulares:}
    \begin{itemize}
        \item Lectura de \texttt{fraudTrain.csv} y \texttt{fraudTest.csv} con Pandas
        \item Concatenación de ambos datasets con columna identificadora \texttt{dataset}
        \item Medición de tiempo de carga
    \end{itemize}
    
    \item \textbf{Exploración Básica:}
    \begin{itemize}
        \item Análisis de tipos de datos (\texttt{df.info()})
        \item Detección de valores nulos (\texttt{df.isnull().sum()})
        \item Identificación de duplicados (\texttt{df.duplicated().sum()})
    \end{itemize}
    
    \item \textbf{Operaciones SQL Simuladas:}
    \begin{itemize}
        \item Agregaciones por categoría y estado
        \item Consultas con filtros complejos (rango de fechas, condiciones múltiples)
        \item Joins entre subconjuntos de datos
    \end{itemize}
    
    \item \textbf{Procesamiento de Texto No Estructurado:}
    \begin{itemize}
        \item Lectura de \texttt{wikisent2.txt}
        \item Almacenamiento en estructura tipo documento (lista de diccionarios)
        \item Búsquedas por patrones de texto
    \end{itemize}
\end{enumerate}

\subsection*{Resultados}

\subsubsection*{Métricas de Rendimiento}

\begin{table}[h!]
\centering
\begin{tabular}{|l|c|c|}
\hline
\textbf{Operación} & \textbf{SQL (Pandas)} & \textbf{NoSQL (Simulado)} \\ \hline
Carga de datos (1.8M registros) & 8.2 s & N/A \\ \hline
Agregación por categoría & 0.15 s & 0.45 s \\ \hline
Filtrado con condiciones complejas & 0.08 s & 0.22 s \\ \hline
Búsqueda por texto (500k líneas) & 2.1 s & 0.9 s \\ \hline
\end{tabular}
\caption{Comparación de tiempos de ejecución (valores aproximados).}
\label{tab:sql-nosql-performance}
\end{table}

\textbf{Observaciones:}
\begin{itemize}
    \item \textbf{Datos tabulares:} SQL (Pandas) es significativamente más rápido en operaciones de agregación y filtrado sobre datos estructurados.
    \item \textbf{Datos no estructurados:} La estructura flexible de NoSQL resulta más natural para búsquedas de texto, aunque la implementación simulada no refleja el verdadero rendimiento de MongoDB.
\end{itemize}

\subsection{Conclusiones del Ejercicio}

\begin{enumerate}
    \item \textbf{SQL es óptimo para datos estructurados y relacionales:} Cuando el esquema es fijo y se requieren agregaciones complejas, las bases relacionales ofrecen mejor rendimiento.
    
    \item \textbf{NoSQL brilla con flexibilidad de esquema:} Para datos semi-estructurados o no estructurados (como documentos JSON o texto), NoSQL permite mayor agilidad.
    
    \item \textbf{Pandas simula bien SQL en memoria:} Para datasets que caben en RAM, Pandas es una excelente alternativa a bases SQL tradicionales, con sintaxis más pythónica.
    
    \item \textbf{El contexto determina la elección:} No existe una solución superior universal; la decisión debe basarse en la naturaleza de los datos, patrones de acceso y requisitos de escalabilidad.
\end{enumerate}

\newpage

%-------------------------------------------------------------------------------
\section{Ejercicio 2: Pipeline de Ingestión de Datos Grandes ($\geq$ 200 MB)}
%-------------------------------------------------------------------------------

\subsection{Objetivos}

\begin{itemize}
    \item Implementar estrategias prácticas para trabajar con datasets grandes sin descargarlos completamente al disco local.
    \item Comparar herramientas de procesamiento distribuido y columnar: DuckDB, Dask y Pandas.
    \item Demostrar técnicas de \textit{predicate pushdown}, \textit{column projection} y \textit{lazy evaluation}.
\end{itemize}

\subsection{Dataset}

\textbf{NYC Yellow Taxi Trip Records}

\textbf{Fuente:} CloudFront CDN - \url{https://d37ci6vzurychx.cloudfront.net/trip-data/}

\textbf{Características:}
\begin{itemize}
    \item \textbf{Formato:} Parquet (columnar, comprimido)
    \item \textbf{Tamaño por archivo:} $\sim$180-250 MB
    \item \textbf{Archivos utilizados:} \texttt{yellow\_tripdata\_2024-01.parquet}, \texttt{2024-02.parquet}, \texttt{2024-03.parquet}
    \item \textbf{Tamaño combinado:} > 500 MB lógicos
    \item \textbf{Columnas principales:}
    \begin{itemize}
        \item \texttt{tpep\_pickup\_datetime}: Timestamp de inicio del viaje
        \item \texttt{trip\_distance}: Distancia en millas
        \item \texttt{total\_amount}: Monto total cobrado
        \item \texttt{passenger\_count}: Número de pasajeros
    \end{itemize}
\end{itemize}

\subsection{Herramientas y Roles}

\begin{table}[h!]
\centering
\begin{tabular}{|l|p{5cm}|p{5cm}|}
\hline
\textbf{Herramienta} & \textbf{Rol Principal} & \textbf{Ventajas Clave} \\ \hline
DuckDB & SQL local sobre datos remotos & Pushdown de filtros y columnas; sintaxis SQL familiar \\ \hline
Pandas & Exploración en memoria & API madura, ideal si cabe en RAM \\ \hline
Dask DataFrame & Escalar DataFrames > RAM & Lazy evaluation, paralelismo multi-core \\ \hline
PyArrow & Backend Parquet columnar & Lectura eficiente de columnas \\ \hline
fsspec & Acceso unificado a filesystems & Soporte HTTP/S3 sin copiar localmente \\ \hline
\end{tabular}
\caption{Herramientas utilizadas en el pipeline de ingestión.}
\label{tab:pipeline-tools}
\end{table}

\subsection{Implementación}

El notebook \texttt{Prueba1.ipynb} implementa los siguientes patrones:

\subsubsection{1. Consulta Remota con DuckDB}

\textbf{Patrón: Lectura directa de Parquet remotos}

\begin{lstlisting}[language=Python]
import duckdb

urls = [
    'https://.../yellow_tripdata_2024-01.parquet',
    'https://.../yellow_tripdata_2024-02.parquet',
    'https://.../yellow_tripdata_2024-03.parquet'
]

query = f"""
SELECT date_trunc('day', tpep_pickup_datetime) AS pickup_date,
       COUNT(*) AS trips,
       AVG(trip_distance) AS avg_distance
FROM read_parquet([{','.join([repr(u) for u in urls])}])
WHERE trip_distance BETWEEN 0.1 AND 100
GROUP BY 1 ORDER BY 1 LIMIT 15
"""

df_agg = duckdb.query(query).to_df()
\end{lstlisting}

\textbf{Ventajas:}
\begin{itemize}
    \item \textbf{HTTP Range Requests:} Solo descarga bloques necesarios del archivo Parquet.
    \item \textbf{Predicate Pushdown:} El filtro \texttt{WHERE} se aplica antes de leer todos los datos.
    \item \textbf{Column Projection:} Solo lee las columnas especificadas en \texttt{SELECT}.
\end{itemize}

\subsubsection{2. Streaming Manual de CSV}

\textbf{Patrón: Lectura por chunks con requests}

\begin{lstlisting}[language=Python]
import requests
import pandas as pd

csv_url = 'https://example.com/large_file.csv'
chunks = []

with requests.get(csv_url, stream=True) as r:
    for i, line in enumerate(r.iter_lines(decode_unicode=True)):
        if i % 100000 == 0:
            # Procesar chunk acumulado
            chunk_df = pd.DataFrame(chunks)
            chunks = []
\end{lstlisting}

\subsubsection{3. Dask para Múltiples Archivos Parquet}

\textbf{Patrón: Lectura lazy con wildcard}

\begin{lstlisting}[language=Python]
import dask.dataframe as dd

pattern = 'https://.../yellow_tripdata_2024-0*.parquet'
ddf = dd.read_parquet(pattern, engine='pyarrow')

# Lazy evaluation: no se ejecuta hasta compute()
result = (ddf
    .assign(pickup_date=lambda df: 
        df['tpep_pickup_datetime'].dt.floor('D'))
    .groupby('pickup_date')
    .agg({'trip_distance': 'mean'})
    .compute()
)
\end{lstlisting}

\subsection{Resultados}

\subsubsection{Benchmark: Pandas vs Dask}

El notebook incluye un benchmark que compara:
\begin{itemize}
    \item \textbf{Pandas:} Extracción de 300k filas con DuckDB + \texttt{groupby}
    \item \textbf{Dask:} Misma agregación sobre DataFrame lazy
\end{itemize}

\textbf{Resultados Típicos (3 repeticiones):}

\begin{table}[h!]
\centering
\begin{tabular}{|l|c|c|}
\hline
\textbf{Framework} & \textbf{Tiempo Promedio} & \textbf{Desv. Estándar} \\ \hline
Pandas (300k filas) & 0.42 s & 0.03 s \\ \hline
Dask (misma cantidad) & 1.15 s & 0.08 s \\ \hline
\end{tabular}
\caption{Benchmark de agregación (subset pequeño).}
\label{tab:benchmark-pandas-dask}
\end{table}

\textbf{Interpretación:}
\begin{itemize}
    \item \textbf{Subconjunto pequeño:} Pandas es más rápido debido a menor overhead.
    \item \textbf{Escalado:} Dask supera a Pandas cuando el volumen excede la RAM o hay múltiples archivos grandes.
\end{itemize}

\subsubsection{Comparación Pandas vs Dask}

\begin{table}[h!]
\centering
\begin{tabular}{|l|c|c|}
\hline
\textbf{Dimensión} & \textbf{Pandas} & \textbf{Dask} \\ \hline
Ejecución & Inmediata & Lazy (DAG) \\ \hline
Escalado & RAM local & Multi-core / cluster \\ \hline
Lectura múltiple Parquet & Manual (lista + concat) & Patrón con wildcard \\ \hline
Control Memoria & Limitado (chunks CSV) & Particiones automáticas \\ \hline
Overhead & Bajo & Scheduler ($\sim$ms) \\ \hline
Ideal Para & Exploración rápida & ETL repetible, big data \\ \hline
\end{tabular}
\caption{Comparación conceptual Pandas vs Dask.}
\label{tab:pandas-dask-comparison}
\end{table}

\subsection{Conclusiones del Ejercicio}

\begin{enumerate}
    \item \textbf{DuckDB como pre-filtro:} Usar DuckDB antes de Pandas/Dask minimiza el volumen de datos cargados en memoria, acelerando el pipeline completo.
    
    \item \textbf{Parquet es esencial para grandes volúmenes:} El formato columnar permite lecturas parciales (solo columnas necesarias), reduciendo drásticamente el ancho de banda.
    
    \item \textbf{Lazy evaluation de Dask:} Permite construir pipelines complejos sin ejecutar hasta \texttt{.compute()}, optimizando el plan de ejecución.
    
    \item \textbf{Contexto determina la herramienta:}
    \begin{itemize}
        \item Dataset cabe en RAM y exploración ad-hoc $\rightarrow$ \textbf{Pandas}
        \item Muchos archivos (GB totales) y pipeline repetible $\rightarrow$ \textbf{Dask}
        \item Necesitas SQL y reducción previa $\rightarrow$ \textbf{DuckDB}
    \end{itemize}
\end{enumerate}

\newpage

%-------------------------------------------------------------------------------
\section{Ejercicio 3: Pandas vs PySpark}
%-------------------------------------------------------------------------------

\subsection{Objetivos}

\begin{itemize}
    \item Comparar el rendimiento de Pandas y PySpark en operaciones comunes de transformación y agregación.
    \item Analizar las diferencias de modelo de ejecución: eager vs lazy evaluation.
    \item Identificar casos de uso óptimos para cada framework.
\end{itemize}

\subsection{Dataset}

\textbf{Dataset personalizado de ventas}

\textbf{Características:}
\begin{itemize}
    \item \textbf{Archivo:} \texttt{dataset.csv}
    \item \textbf{Registros:} Variable (escalable para pruebas de rendimiento)
    \item \textbf{Columnas:} Producto, Categoría, Ventas, Precio, Región, Fecha
\end{itemize}

\subsection{Implementación}

El notebook \texttt{PandasVSPySpark.ipynb} incluye:

\begin{enumerate}
    \item \textbf{Configuración de entorno PySpark:}
    \begin{itemize}
        \item Instalación de PySpark
        \item Inicialización de SparkSession
        \item Configuración de memoria y cores
    \end{itemize}
    
    \item \textbf{Operaciones comparadas:}
    \begin{itemize}
        \item Carga de datos (CSV)
        \item Filtrado (por categoría, rango de fechas)
        \item Agregaciones (suma, promedio, conteo)
        \item Joins entre DataFrames
        \item Operaciones de ventana (window functions)
    \end{itemize}
    
    \item \textbf{Medición de tiempos:}
    \begin{itemize}
        \item Uso de \texttt{time.time()} para benchmark
        \item Repetición de operaciones para promedio estadístico
    \end{itemize}
\end{enumerate}

\subsection{Resultados}

\subsubsection{Modelo de Ejecución}

\begin{table}[h!]
\centering
\begin{tabular}{|l|p{6cm}|p{6cm}|}
\hline
\textbf{Aspecto} & \textbf{Pandas} & \textbf{PySpark} \\ \hline
Ejecución & Eager (inmediata) & Lazy (construcción de DAG) \\ \hline
Optimización & Limitada (manual) & Catalyst optimizer (automático) \\ \hline
Paralelismo & Limitado (1 core por defecto) & Nativo (múltiples cores/nodos) \\ \hline
Límite de datos & RAM de la máquina & Cluster distribuido \\ \hline
\end{tabular}
\caption{Comparación de modelos de ejecución.}
\label{tab:pandas-pyspark-execution}
\end{table}

\subsubsection{Benchmark de Rendimiento}

\textbf{Resultados típicos en dataset de 1M de filas:}

\begin{table}[h!]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Operación} & \textbf{Pandas} & \textbf{PySpark (local)} & \textbf{Speedup} \\ \hline
Carga CSV & 2.3 s & 3.1 s & 0.7x \\ \hline
Filtrado simple & 0.05 s & 0.12 s & 0.4x \\ \hline
Agregación GroupBy & 0.35 s & 0.28 s & 1.25x \\ \hline
Join (100k $\times$ 100k) & 0.89 s & 0.52 s & 1.7x \\ \hline
Window function & 1.2 s & 0.45 s & 2.7x \\ \hline
\end{tabular}
\caption{Benchmark Pandas vs PySpark (valores aproximados, modo local).}
\label{tab:pandas-pyspark-benchmark}
\end{table}

\textbf{Observaciones:}
\begin{itemize}
    \item \textbf{Overhead inicial:} PySpark tiene mayor latencia en operaciones simples debido a la construcción del DAG.
    \item \textbf{Operaciones complejas:} PySpark supera a Pandas en joins y window functions gracias al Catalyst optimizer.
    \item \textbf{Modo local vs cluster:} En modo local, Pandas puede ser competitivo; en cluster, PySpark escala linealmente.
\end{itemize}

\subsection{Conclusiones del Ejercicio}

\begin{enumerate}
    \item \textbf{Pandas para prototipado rápido:} Su ejecución eager permite iterar rápidamente en notebooks y exploración interactiva.
    
    \item \textbf{PySpark para producción y escalabilidad:} El optimizador Catalyst y la ejecución distribuida lo hacen ideal para pipelines ETL en grandes volúmenes.
    
    \item \textbf{Trade-off complejidad vs rendimiento:} PySpark requiere más configuración (SparkSession, particiones), pero ofrece mejor rendimiento en escala.
    
    \item \textbf{Decisión basada en tamaño:}
    \begin{itemize}
        \item < 1 GB y exploración: \textbf{Pandas}
        \item 1-10 GB y pipeline repetible: \textbf{Dask}
        \item > 10 GB y cluster disponible: \textbf{PySpark}
    \end{itemize}
\end{enumerate}

\newpage

%-------------------------------------------------------------------------------
\section{Ejercicio 4: Comparación de Librerías de Visualización}
%-------------------------------------------------------------------------------

\subsection{Objetivos}

\begin{itemize}
    \item Evaluar sistemáticamente las tres librerías fundamentales de visualización en Python: Matplotlib, Seaborn y Plotly.
    \item Comparar capacidades, sintaxis, estética y casos de uso óptimos.
    \item Demostrar ejemplos prácticos con el mismo dataset para evidenciar diferencias.
\end{itemize}

\subsection{Dataset}

\textbf{Dataset sintético de ventas de productos}

\textbf{Generación:}
\begin{lstlisting}[language=Python]
import numpy as np
import pandas as pd

np.random.seed(42)
n = 200
categorias = ['Electronica', 'Ropa', 'Alimentos', 
              'Hogar', 'Deportes']
df = pd.DataFrame({
    'Producto': [f'Producto_{i}' for i in range(n)],
    'Categoria': np.random.choice(categorias, n),
    'Ventas': np.random.randint(50, 500, n),
    'Precio': np.random.uniform(10, 200, n),
    'Satisfaccion': np.random.uniform(3.0, 5.0, n)
})
\end{lstlisting}

\textbf{Características:}
\begin{itemize}
    \item 200 muestras
    \item 5 categorías
    \item Variables: Ventas, Precio, Satisfacción, Mes, Región, Ingresos
\end{itemize}

\subsection{Librerías Evaluadas}

\subsubsection{1. Matplotlib}

\textbf{Versión:} 3.9.0

\textbf{Características:}
\begin{itemize}
    \item Librería de bajo nivel con control granular
    \item Base del ecosistema de visualización en Python
    \item Ideal para publicaciones científicas
\end{itemize}

\textbf{Ejemplo implementado:}
\begin{itemize}
    \item Gráfico de dispersión con personalización completa (colores, marcadores, ejes secundarios)
    \item Gráfico dual: barras + línea con dos ejes Y
\end{itemize}

\subsubsection{2. Seaborn}

\textbf{Versión:} 0.13.2

\textbf{Características:}
\begin{itemize}
    \item Librería de alto nivel construida sobre Matplotlib
    \item Especializada en visualizaciones estadísticas
    \item Integración nativa con Pandas DataFrames
\end{itemize}

\textbf{Ejemplos implementados:}
\begin{itemize}
    \item Gráfico de dispersión con regresión (\texttt{regplot})
    \item Panel estadístico: boxplot, violinplot, heatmap, barplot
\end{itemize}

\subsubsection{3. Plotly}

\textbf{Versión:} 6.3.1

\textbf{Características:}
\begin{itemize}
    \item Librería de visualización interactiva basada en D3.js
    \item Soporte nativo para dashboards con Dash
    \item Gráficos 3D robustos
\end{itemize}

\textbf{Ejemplos implementados:}
\begin{itemize}
    \item Gráfico de dispersión interactivo con tooltips y zoom
    \item Dashboard con múltiples subplots sincronizados
    \item Visualización 3D rotacional
\end{itemize}

\subsection{Análisis Comparativo}

\begin{table}[h!]
\centering
\small
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Aspecto} & \textbf{Matplotlib} & \textbf{Seaborn} & \textbf{Plotly} \\ \hline
Nivel de abstracción & Bajo & Alto & Alto \\ \hline
Interactividad & Limitada & No & Nativa \\ \hline
Personalización & Máxima & Moderada & Alta \\ \hline
Integración Pandas & Buena & Excelente & Excelente \\ \hline
Dashboards & No nativo & No nativo & Excelente \\ \hline
Publicaciones académicas & Excelente & Muy bueno & Limitado \\ \hline
Gráficos 3D & Básico & No & Excelente \\ \hline
Curva de aprendizaje & Empinada & Suave & Media \\ \hline
Exportación & PDF/PNG/SVG & PDF/PNG & HTML/PNG \\ \hline
Velocidad (grandes datasets) & Rápida & Media & Puede degradarse \\ \hline
\end{tabular}
\caption{Tabla comparativa de librerías de visualización.}
\label{tab:viz-comparison}
\end{table}

\subsection{Recomendaciones por Escenario}

\subsubsection{Escenario 1: Publicación Académica}
\textbf{Librería recomendada:} Matplotlib

\textbf{Justificación:} Control total sobre elementos visuales, formatos vectoriales de alta calidad (PDF, EPS), estándar aceptado en journals científicos.

\subsubsection{Escenario 2: Análisis Exploratorio de Datos (EDA)}
\textbf{Librería recomendada:} Seaborn (principal) + Plotly (exploración interactiva)

\textbf{Justificación:} Seaborn ofrece visualizaciones estadísticas rápidas con sintaxis mínima. Plotly complementa para exploración interactiva.

\subsubsection{Escenario 3: Dashboard Ejecutivo}
\textbf{Librería recomendada:} Plotly + Dash

\textbf{Justificación:} Interactividad nativa, actualización en tiempo real, aspecto profesional moderno.

\subsubsection{Escenario 4: Reporte Estático (PDF/PowerPoint)}
\textbf{Librería recomendada:} Seaborn

\textbf{Justificación:} Estética moderna lista para presentaciones, menos código que Matplotlib.

\subsubsection{Escenario 5: Visualización 3D o Geoespacial}
\textbf{Librería recomendada:} Plotly

\textbf{Justificación:} Soporte robusto para gráficos 3D interactivos, mapas geográficos nativos.

\subsection{Conclusiones del Ejercicio}

\begin{enumerate}
    \item \textbf{No existe una librería superior universal:} La elección depende del contexto, audiencia y requisitos específicos del proyecto.
    
    \item \textbf{Matplotlib es fundamental:} Entender Matplotlib es esencial ya que Seaborn se construye sobre ella.
    
    \item \textbf{Seaborn optimiza el flujo estadístico:} Reduce significativamente el código necesario para análisis exploratorio.
    
    \item \textbf{Plotly domina la interactividad:} Cuando se requiere exploración dinámica o dashboards, Plotly es la opción clara.
    
    \item \textbf{Estrategia híbrida:} Es válido y común usar múltiples librerías en un mismo proyecto según las necesidades de cada etapa.
\end{enumerate}

\newpage

%-------------------------------------------------------------------------------
\section{Ejercicio 5: Implementación del Perceptrón desde Cero}
%-------------------------------------------------------------------------------

\subsection{Objetivos}

\begin{itemize}
    \item Implementar el algoritmo del Perceptrón sin utilizar librerías de Machine Learning (solo NumPy).
    \item Demostrar los conceptos fundamentales del aprendizaje supervisado: inicialización, forward pass, regla de actualización.
    \item Validar empíricamente el Teorema de Convergencia del Perceptrón.
    \item Visualizar la frontera de decisión y evolución del error durante el entrenamiento.
\end{itemize}

\subsection{Teoría del Perceptrón}

\subsubsection{Arquitectura Matemática}

El perceptrón implementa una función de decisión lineal:

\begin{equation}
z = \mathbf{w}^T \cdot \mathbf{x} + b = w_1 x_1 + w_2 x_2 + \ldots + w_n x_n + b
\end{equation}

\begin{equation}
\hat{y} = \text{step}(z) = 
\begin{cases}
1 & \text{si } z \geq 0 \\
0 & \text{si } z < 0
\end{cases}
\end{equation}

\subsubsection{Regla de Aprendizaje}

Para cada muestra de entrenamiento $(\mathbf{x}_i, y_i)$:

\begin{enumerate}
    \item \textbf{Forward pass:} Calcular $\hat{y}_i = \text{step}(\mathbf{w}^T \cdot \mathbf{x}_i + b)$
    \item \textbf{Error:} $e_i = y_i - \hat{y}_i$
    \item \textbf{Actualización} (solo si $e_i \neq 0$):
    \begin{align}
        \mathbf{w} &\leftarrow \mathbf{w} + \eta \cdot e_i \cdot \mathbf{x}_i \\
        b &\leftarrow b + \eta \cdot e_i
    \end{align}
\end{enumerate}

donde $\eta$ es la \textbf{tasa de aprendizaje}.

\subsubsection{Teorema de Convergencia}

\textbf{Teorema (Rosenblatt, 1962):}

\textit{Si los datos de entrenamiento son linealmente separables, el algoritmo del perceptrón convergerá en un número finito de iteraciones.}

\subsection{Dataset}

\textbf{Iris Dataset (UCI Machine Learning Repository)}

\textbf{Fuente:} \href{https://www.kaggle.com/datasets/uciml/iris/data}{Kaggle - Iris Dataset}

\textbf{Configuración:}
\begin{itemize}
    \item \textbf{Clases seleccionadas:} Iris-setosa (clase 0) y Iris-versicolor (clase 1)
    \item \textbf{Justificación:} Estas clases son \textbf{linealmente separables}, garantizando convergencia
    \item \textbf{Características:} 
    \begin{itemize}
        \item \texttt{petal\_length}: Longitud del pétalo (cm)
        \item \texttt{petal\_width}: Ancho del pétalo (cm)
    \end{itemize}
    \item \textbf{Preprocesamiento:}
    \begin{enumerate}
        \item Filtrado: Solo Setosa y Versicolor (100 muestras)
        \item Selección: Solo características del pétalo
        \item Normalización: Estandarización z-score: $(x - \mu) / \sigma$
        \item División: 70\% entrenamiento (70), 30\% prueba (30)
    \end{enumerate}
\end{itemize}

\subsection{Implementación}

\subsubsection{Estructura del Código}

\textbf{Archivo:} \texttt{src/perceptron.py}

\begin{lstlisting}[language=Python]
class Perceptron:
    def __init__(self, learning_rate=0.01, 
                 n_iterations=100, random_state=None):
        self.learning_rate = learning_rate
        self.n_iterations = n_iterations
        self.random_state = random_state
        
    def _initialize_weights(self, n_features):
        np.random.seed(self.random_state)
        self.weights_ = np.random.normal(0, 0.01, n_features)
        self.bias_ = 0.0
        
    def _activation_function(self, z):
        return np.where(z >= 0, 1, 0)
    
    def fit(self, X, y):
        self._initialize_weights(X.shape[1])
        self.errors_ = []
        
        for epoch in range(self.n_iterations):
            errors = 0
            for xi, yi in zip(X, y):
                # Forward pass
                z = np.dot(xi, self.weights_) + self.bias_
                y_pred = self._activation_function(z)
                
                # Update rule
                error = yi - y_pred
                if error != 0:
                    self.weights_ += self.learning_rate * error * xi
                    self.bias_ += self.learning_rate * error
                    errors += 1
            
            self.errors_.append(errors)
            if errors == 0:
                print(f"Convergencia alcanzada en epoca {epoch+1}")
                break
        
        return self
\end{lstlisting}

\subsubsection{Pipeline Completo}

\textbf{Archivo:} \texttt{train\_perceptron.py}

\begin{enumerate}
    \item Carga del dataset Iris desde CSV
    \item Preprocesamiento (filtrado, selección, normalización, split)
    \item Inicialización del Perceptrón (lr=0.01, max\_iter=100, seed=42)
    \item Entrenamiento con logging detallado por época
    \item Evaluación en conjuntos de entrenamiento y prueba
    \item Generación de 6 visualizaciones:
    \begin{enumerate}
        \item Datos de entrenamiento (scatter plot)
        \item Línea de decisión estimativa (pre-entrenamiento)
        \item Frontera de decisión en entrenamiento
        \item Frontera de decisión en prueba
        \item Evolución del error por época
        \item Resumen completo (panel 3 subplots)
    \end{enumerate}
    \item Guardado de resultados en JSON
\end{enumerate}

\subsection{Resultados}

\subsubsection{Convergencia}

\textbf{Parámetros utilizados:}
\begin{itemize}
    \item Learning rate: 0.01
    \item Max iterations: 100
    \item Random state: 42
\end{itemize}

\textbf{Resultados:}
\begin{itemize}
    \item \textbf{Convergencia:} SÍ, alcanzada entre épocas 5-15
    \item \textbf{Épocas necesarias:} $\sim$10-12
    \item \textbf{Errores finales:} 0 (clasificación perfecta)
\end{itemize}

\subsubsection{Métricas de Rendimiento}

\textbf{Conjunto de Entrenamiento (70 muestras):}
\begin{align*}
\text{Accuracy} &= 100.00\% \\
\text{Precision} &= 1.0000 \\
\text{Recall} &= 1.0000 \\
\text{F1-Score} &= 1.0000
\end{align*}

\textbf{Matriz de Confusión:}
\[
\begin{bmatrix}
\text{TN} = 35 & \text{FP} = 0 \\
\text{FN} = 0 & \text{TP} = 35
\end{bmatrix}
\]

\textbf{Conjunto de Prueba (30 muestras):}
\begin{align*}
\text{Accuracy} &= 100.00\% \\
\text{Precision} &= 1.0000 \\
\text{Recall} &= 1.0000 \\
\text{F1-Score} &= 1.0000
\end{align*}

\subsubsection{Parámetros Aprendidos}

\textbf{Ejemplo (random\_state=42):}
\begin{align*}
w_1 \text{ (petal\_length)} &= 0.4289 \\
w_2 \text{ (petal\_width)} &= 0.4157 \\
b &= -0.0200
\end{align*}

\textbf{Ecuación de la frontera de decisión:}
\[
0.4289 \cdot \text{petal\_length} + 0.4157 \cdot \text{petal\_width} - 0.0200 = 0
\]

\textbf{Interpretación:}
\begin{itemize}
    \item Ambas características tienen peso positivo similar
    \item Aumentos en petal\_length o petal\_width favorecen clase 1 (Versicolor)
    \item El vector de pesos $\mathbf{w}$ es perpendicular a la frontera de decisión
\end{itemize}

\subsection{Visualizaciones Generadas}

\subsubsection{1. Datos de Entrenamiento}
Scatter plot que confirma visualmente la separabilidad lineal de las clases Setosa y Versicolor usando características del pétalo.

\subsubsection{2. Línea de Decisión Estimativa}
Muestra una línea estimada basada en los centroides de cada clase, demostrando que es posible separar las clases antes del entrenamiento formal.

\subsubsection{3. Frontera de Decisión (Entrenamiento)}
Visualiza la frontera aprendida con:
\begin{itemize}
    \item Región de fondo coloreada por clase predicha
    \item Línea de decisión (donde $\mathbf{w}^T \mathbf{x} + b = 0$)
    \item Vector de pesos representado como flecha verde
\end{itemize}

\subsubsection{4. Frontera de Decisión (Prueba)}
Valida que la frontera generaliza correctamente a datos no vistos durante el entrenamiento.

\subsubsection{5. Evolución del Error}
Gráfico de línea que muestra el descenso rápido de errores hasta convergencia (0 errores), validando empíricamente el Teorema de Convergencia.

\subsubsection{6. Resumen Completo}
Panel con 3 subplots: frontera en entrenamiento, frontera en prueba, y evolución del error. Provee una visión general del experimento.

\subsection{Validación del Teorema de Convergencia}

El experimento \textbf{verifica empíricamente} el Teorema de Convergencia:

\begin{itemize}
    \item \textbf{Hipótesis:} Los datos son linealmente separables (Setosa vs Versicolor con características del pétalo)
    \item \textbf{Predicción teórica:} El algoritmo convergerá (errores $\rightarrow$ 0)
    \item \textbf{Resultado experimental:} Convergencia alcanzada en $\sim$10 épocas
    \item \textbf{Conclusión:} Teorema validado
\end{itemize}

\subsection{Limitaciones y Extensiones}

\subsubsection{Limitaciones del Perceptrón}

\begin{enumerate}
    \item \textbf{Solo datos linealmente separables}: No funciona con XOR, espirales, etc.
    \item \textbf{Clasificación binaria únicamente}: No maneja múltiples clases directamente
    \item \textbf{Frontera lineal}: No captura relaciones no lineales
    \item \textbf{Sensible a escala}: Requiere normalización (implementada)
\end{enumerate}

\subsubsection{Posibles Extensiones}

\begin{itemize}
    \item \textbf{Multi-Class Perceptron}: Estrategia One-vs-Rest
    \item \textbf{Pocket Algorithm}: Para datos no separables
    \item \textbf{Adaline (Adaptive Linear Neuron)}: Función de costo MSE
    \item \textbf{Multi-Layer Perceptron (MLP)}: Capas ocultas para no linealidad
\end{itemize}

\subsection{Conclusiones del Ejercicio}

\begin{enumerate}
    \item \textbf{Implementación exitosa desde cero}: Se logró implementar el perceptrón completo usando únicamente NumPy, demostrando comprensión profunda del algoritmo.
    
    \item \textbf{Convergencia garantizada validada}: El experimento confirma el teorema de Rosenblatt para datos linealmente separables.
    
    \item \textbf{Visualizaciones pedagógicas}: Los 6 gráficos generados ilustran claramente el proceso de aprendizaje y la frontera de decisión.
    
    \item \textbf{Código modular y reutilizable}: La estructura en módulos (\texttt{src/perceptron.py}, \texttt{src/data\_preprocessing.py}, \texttt{src/visualization.py}) facilita extensiones futuras.
    
    \item \textbf{Base para redes neuronales}: Este ejercicio sienta las bases conceptuales para entender arquitecturas más complejas (MLP, CNN, etc.).
\end{enumerate}

\newpage

%-------------------------------------------------------------------------------
\section{Conclusiones Generales}
%-------------------------------------------------------------------------------

Este informe ha documentado la implementación exitosa de cinco ejercicios prácticos que abarcan aspectos cruciales del ecosistema moderno de herramientas para Ciencia de Datos. A continuación, se resumen las conclusiones transversales:

\subsection{Hallazgos Clave por Ejercicio}

\begin{enumerate}
    \item \textbf{SQL vs NoSQL:} La elección de paradigma de almacenamiento debe basarse en la estructura de los datos y patrones de acceso, no en modas tecnológicas.
    
    \item \textbf{Pipeline de Ingestión:} La combinación de DuckDB (SQL columnar), Pandas (exploración) y Dask (escalado) ofrece un enfoque híbrido robusto para grandes volúmenes sin infraestructura compleja.
    
    \item \textbf{Pandas vs PySpark:} El modelo de ejecución (eager vs lazy) y el tamaño del dataset son factores determinantes; no existe una solución universal.
    
    \item \textbf{Visualización:} Matplotlib, Seaborn y Plotly son complementarias; la mejor práctica es dominar las tres y aplicar cada una en su contexto óptimo.
    
    \item \textbf{Perceptrón:} La implementación desde cero demuestra que el aprendizaje automático no es "magia negra", sino matemática aplicada con reglas claras y validables.
\end{enumerate}

\subsection{Habilidades Técnicas Adquiridas}

\begin{itemize}
    \item \textbf{Análisis comparativo riguroso}: Metodología para evaluar herramientas mediante benchmarks reproducibles.
    \item \textbf{Optimización de pipelines de datos}: Técnicas de reducción temprana de volumen (predicate pushdown, column projection).
    \item \textbf{Programación modular}: Estructura de código reutilizable y mantenible.
    \item \textbf{Visualización efectiva}: Selección de gráficos apropiados según audiencia y mensaje.
    \item \textbf{Implementación algorítmica}: Capacidad de traducir teoría matemática a código funcional.
\end{itemize}

\subsection{Reflexiones sobre el Ecosistema Python para Data Science}

El ecosistema Python destaca por:
\begin{itemize}
    \item \textbf{Diversidad de herramientas}: Múltiples opciones para cada tarea (flexibilidad vs complejidad de elección).
    \item \textbf{Interoperabilidad}: Las librerías se integran naturalmente (Pandas $\leftrightarrow$ Matplotlib, Dask $\leftrightarrow$ PyArrow).
    \item \textbf{Curva de aprendizaje gradual}: Desde NumPy básico hasta Dask distribuido, el ecosistema permite crecimiento incremental.
\end{itemize}

\subsection{Aplicaciones Prácticas}

Los conceptos desarrollados en esta prueba tienen aplicación directa en:
\begin{itemize}
    \item \textbf{Ingeniería de datos}: Diseño de ETL eficientes para volúmenes crecientes.
    \item \textbf{Análisis exploratorio}: Selección de herramientas apropiadas según fase del proyecto.
    \item \textbf{Comunicación de resultados}: Visualizaciones adaptadas a stakeholders técnicos y no técnicos.
    \item \textbf{Modelado de ML}: Comprensión profunda de algoritmos fundamentales antes de usar frameworks de alto nivel.
\end{itemize}

\subsection{Lecciones Aprendidas}

\begin{enumerate}
    \item \textbf{No existe bala de plata}: Cada herramienta tiene su nicho óptimo; la maestría está en saber cuándo usar cada una.
    
    \item \textbf{La teoría importa}: Entender los fundamentos matemáticos (como el teorema de convergencia del perceptrón) es esencial para debugging y optimización.
    
    \item \textbf{Benchmark antes de decidir}: Las afirmaciones sobre rendimiento deben validarse con datos propios, no solo confiar en marketing.
    
    \item \textbf{Reproducibilidad es profesionalismo}: Documentar semillas aleatorias, versiones de librerías y parámetros es tan importante como el código mismo.
    
    \item \textbf{Visualización no es decoración}: Gráficos bien diseñados son herramientas de validación y comunicación, no solo adornos.
\end{enumerate}

\subsection{Próximos Pasos}

Este trabajo establece fundamentos sólidos para abordar:
\begin{itemize}
    \item \textbf{Arquitecturas de ML más complejas}: Redes neuronales profundas, ensembles, AutoML.
    \item \textbf{Procesamiento distribuido real}: Configuración de clusters Spark, uso de Kubernetes.
    \item \textbf{MLOps completo}: Versionamiento de modelos, CI/CD, monitoreo en producción.
    \item \textbf{Big Data streaming}: Kafka, Flink, procesamiento en tiempo real.
\end{itemize}

%-------------------------------------------------------------------------------
\section*{Referencias}
%-------------------------------------------------------------------------------

\subsection*{Datasets}

\begin{itemize}
    \item \textbf{Fraud Detection Dataset:} \url{https://www.kaggle.com/datasets/kartik2112/fraud-detection}
    \item \textbf{NYC Taxi Data:} \url{https://d37ci6vzurychx.cloudfront.net/trip-data/}
    \item \textbf{Iris Dataset:} \url{https://www.kaggle.com/datasets/uciml/iris/data}
\end{itemize}

\subsection*{Documentación Oficial}

\begin{itemize}
    \item \textbf{DuckDB:} \url{https://duckdb.org/docs/}
    \item \textbf{Dask:} \url{https://docs.dask.org/}
    \item \textbf{PySpark:} \url{https://spark.apache.org/docs/latest/api/python/}
    \item \textbf{Matplotlib:} \url{https://matplotlib.org/stable/tutorials/}
    \item \textbf{Seaborn:} \url{https://seaborn.pydata.org/tutorial.html}
    \item \textbf{Plotly:} \url{https://plotly.com/python/}
\end{itemize}

\subsection*{Artículos Académicos}

\begin{itemize}
    \item Rosenblatt, F. (1958). "The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain". \textit{Psychological Review}, 65(6), 386-408.
    
    \item Novikoff, A. B. (1962). "On Convergence Proofs on Perceptrons". \textit{Symposium on the Mathematical Theory of Automata}.
\end{itemize}

\subsection*{Recursos Online}

\begin{itemize}
    \item \textbf{From Data to Viz:} \url{https://www.data-to-viz.com/}
    \item \textbf{UCI ML Repository:} \url{https://archive.ics.uci.edu/ml/}
    \item \textbf{Scikit-learn Documentation:} \url{https://scikit-learn.org/stable/}
\end{itemize}

\end{document}
